import logging
import time
import os
import traceback
from celery import shared_task
from ai.services.news_briefing_service import NewsBriefingService


logger = logging.getLogger(__name__)

@shared_task
def debug_env_vars():
    """è°ƒè¯•ç¯å¢ƒå˜é‡çš„ä»»åŠ¡"""
    try:
        # æ£€æŸ¥æ‰€æœ‰ç¯å¢ƒå˜é‡
        openai_key = os.environ.get('OPENAI_API_KEY')
        openai_key_getenv = os.getenv('OPENAI_API_KEY')
        
        logger.info(f"os.environ.get('OPENAI_API_KEY'): {openai_key[:10] if openai_key else 'None'}...")
        logger.info(f"os.getenv('OPENAI_API_KEY'): {openai_key_getenv[:10] if openai_key_getenv else 'None'}...")
        
        # æ£€æŸ¥ Django settings
        try:
            from django.conf import settings
            settings_key = getattr(settings, 'OPENAI_API_KEY', 'Not found')
            logger.info(f"Django settings OPENAI_API_KEY: {settings_key[:10] if settings_key and settings_key != 'Not found' else settings_key}...")
        except Exception as e:
            logger.error(f"Django settings error: {e}")
        
        # æ‰“å°æ‰€æœ‰ç¯å¢ƒå˜é‡ä¸­åŒ…å« OPENAI çš„
        openai_vars = {k: v for k, v in os.environ.items() if 'OPENAI' in k}
        logger.info(f"æ‰€æœ‰åŒ…å« OPENAI çš„ç¯å¢ƒå˜é‡: {list(openai_vars.keys())}")
        
        return {
            'environ_get': openai_key[:10] if openai_key else None,
            'getenv': openai_key_getenv[:10] if openai_key_getenv else None,
            'all_openai_vars': list(openai_vars.keys())
        }
    except Exception as e:
        logger.error(f"è°ƒè¯•ç¯å¢ƒå˜é‡æ—¶å‡ºé”™: {e}")
        return f"Error: {e}"


@shared_task
def debug_task_test(message, duration = 5):
    logger.info(f"------CELERY DEBUG TASK------")
    logger.info(f'Request: {message!r}')
    print(f"Duration: {duration}")
    time.sleep(duration)
    print(f"Task Complete")
    

@shared_task(bind=True, max_retries=3, default_retry_delay=300)
def fetch_and_process_news(self):
    """
    å‘¨æœŸæ€§ä»»åŠ¡ï¼šä»RSSæºæŠ“å–æ–°é—»å¹¶å¤„ç†åµŒå…¥ã€‚
    """
    
    try:
        from ai.services.news_briefing_service import NewsBriefingService
        service = NewsBriefingService() 
        logger.info(f"{self.__class__.__name__}: å®ä¾‹åˆ›å»ºæˆåŠŸ: {type(service)}, æ­£åœ¨æŠ“å–æ–°é—»...")
        result = service.fetch_news_and_embedding()
        if result.get('error'):
            logger.error(f"{self.__class__.__name__}: æŠ“å–æ–°é—»æ—¶å‡ºé”™: {result['error']}")
            raise Exception(result['error'])
        logger.info(f"{self.__class__.__name__}: æˆåŠŸæŠ“å– {len(result.get('articles', []))} ç¯‡æ–‡ç« .")
    except Exception as e:
        logger.error(f"{self.__class__.__name__}: fetch_and_process_news ä»»åŠ¡å‡ºé”™: {str(e)}")
        self.retry(exc=e)
        
        
@shared_task(bind=True, max_retries=3, default_retry_delay=600)
def generate_user_news_briefing_task(self, report_id: int):
    """
    å‘¨æœŸæ€§ä»»åŠ¡ï¼šä¸ºç”¨æˆ·ç”Ÿæˆæ–°é—»ç®€æŠ¥ã€‚
    """
    logger.info(f"{self.__class__.__name__}: ğŸš€ [TASK START] æŠ¥å‘Š: {report_id} Task å¼€å§‹")

    try:
        from ai.services.news_briefing_service import NewsBriefingService
        logger.info(f"{self.__class__.__name__}: âœ… [STEP 1] å¼€å§‹æ‰§è¡Œä»»åŠ¡: generate_user_news_briefing_task, æŠ¥å‘Š ID: {report_id}")

        service = NewsBriefingService()
        logger.info(f"{self.__class__.__name__}: âœ… [STEP 2] å®ä¾‹åˆ›å»ºæˆåŠŸ: {type(service)}")

        report_instance = service.process_briefing_generation(report_id)
        logger.info(f"{self.__class__.__name__}: âœ… [STEP 3] æ–¹æ³•è°ƒç”¨æˆåŠŸï¼Œè¿”å›: {report_instance}")


        if not report_instance:
            logger.error(f"{self.__class__.__name__}: âŒ [STEP 4] è¿”å› None")
            raise Exception("Failed to process news briefing generation.")

        logger.info(f"{self.__class__.__name__}: ğŸ“Š [STEP 4] æŠ¥å‘ŠçŠ¶æ€: {report_instance.status}")
        if report_instance.status == 'completed':
            logger.info(f"{self.__class__.__name__}: ğŸ‰ [SUCCESS] æŠ¥å‘Š {report_id} ç”ŸæˆæˆåŠŸ")
                # ä½¿ç”¨æ¨¡å‹çš„åºåˆ—åŒ–æ–¹æ³•
            return {
                 "status": "success",
                "report_data": report_instance.to_celery_dict()
            }
        else:
            error_msg = f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {report_instance.error_message}"
            logger.error(f"{self.__class__.__name__}: âŒ ç”Ÿæˆå¤±è´¥[ERROR] {error_msg}")
            raise Exception(f"News briefing generation failed: {report_instance.error_message}")
        
    except Exception as e:
        logger.error("ğŸ’¥" * 20)
        logger.error(f"{self.__class__.__name__}: âŒ [ERROR] ä»»åŠ¡å¤±è´¥ - æŠ¥å‘Š ID {report_id}")
        logger.error(f"{self.__class__.__name__}: âŒ [ERROR] é”™è¯¯ä¿¡æ¯: {str(e)}")
        logger.error(f"{self.__class__.__name__}: âŒ [ERROR] é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"{self.__class__.__name__}: Error in generate_user_news_briefing_task for report ID {report_id}: {str(e)}")
        if "'module' object is not callable" in str(e):
            logger.error(f"{self.__class__.__name__}: ğŸ” [ANALYSIS] 'module' object is not callable é”™è¯¯")
            logger.error(f"{self.__class__.__name__}: ğŸ’¡ [HINT] æ£€æŸ¥æ˜¯å¦æœ‰è¯­æ³•é”™è¯¯æˆ–å¯¼å…¥é—®é¢˜")

        # å®Œæ•´å †æ ˆè¿½è¸ª
        logger.error(f"{self.__class__.__name__}: ğŸ“‹ [TRACEBACK] å®Œæ•´é”™è¯¯å †æ ˆ:")
        for line in traceback.format_exc().split('\n'):
            if line.strip():
                logger.error(f"    {line}")
        
        logger.error("ğŸ’¥" * 20)
        self.retry(exc=e)
    
@shared_task(bind=True, max_retries=3, default_retry_delay=300)
def update_user_profile_embedding_task(self, profile_id: int):
    """
    å¼‚æ­¥æ›´æ–°ç”¨æˆ·ç”»åƒçš„åµŒå…¥å‘é‡
    """
    try:
        from apps.users.models import UserProfile
        from ai.vector.user_vector_executor import UserVectorExecutor

        logger.info(f"{self.__class__.__name__}: å¼€å§‹æ›´æ–°ç”¨æˆ·ç”»åƒ {profile_id} çš„åµŒå…¥å‘é‡")

        profile = UserProfile.objects.get(id=profile_id)
        user_vector_executor = UserVectorExecutor()
        
        # æ„å»ºç”¨äºåµŒå…¥çš„æ–‡æœ¬
        portrait = profile.user_self_portrait or "æŠ•èµ„è€…"
        topics = ", ".join(profile.preferred_topic) if profile.preferred_topic else "è´¢ç»"
        topic_text = profile.perferred_topic_text or "å…³æ³¨è´¢ç»å¸‚åœº"
        
        text_for_embedding = f"{portrait}ã€‚{topic_text}ã€‚å…³æ³¨è¯é¢˜ï¼š{topics}"
        
        # æ›´æ–°åµŒå…¥å‘é‡
        success = user_vector_executor.update_user_profile_embedding(
            profile, text_for_embedding
        )
        
        if success:
            logger.info(f"{self.__class__.__name__}: ç”¨æˆ·ç”»åƒ {profile_id} çš„åµŒå…¥å‘é‡æ›´æ–°æˆåŠŸ")
            return {"status": "success", "profile_id": profile_id}
        else:
            logger.error(f"{self.__class__.__name__}: ç”¨æˆ·ç”»åƒ {profile_id} çš„åµŒå…¥å‘é‡æ›´æ–°å¤±è´¥")
            return {"status": "failed", "profile_id": profile_id}
            
    except UserProfile.DoesNotExist:
        logger.error(f"{self.__class__.__name__}: ç”¨æˆ·ç”»åƒ {profile_id} ä¸å­˜åœ¨")
        return {"status": "not_found", "profile_id": profile_id}
    except Exception as e:
        logger.error(f"{self.__class__.__name__}: æ›´æ–°ç”¨æˆ·ç”»åƒ {profile_id} åµŒå…¥å‘é‡æ—¶å‡ºé”™: {e}")
        return {"status": "error", "profile_id": profile_id, "error": str(e)}
